Este papper trata de encontrar a través 121 conjuntos de bases de datos cual es el mejor clasificador en los cuales estandarizaron las variables como es habitual en estos métodos y no experimentaron otro tipo de estandarización pues el conocimiento de estos conjunto de datos requerían una mejor conocimiento que esta fuera del alcance de los investigadores, ellos no buscaron rendimiento en cada posible conjunto de datos sino encontrar el mejor clasificador para ello siguieron un orden para no generar sesgo a la hora de generar los algoritmos y/o entrenamiento, también los datos faltante lo catalogaron como cero y esto no debería segar los resultado de comparación, ellos utilizaron 172 clasificadores implementados en C,C++, Matlab, R y Weka, como resultado del proceso del trabajo experimental, evaluaron 179 clasificadores en más de 121 conjuntos de datos, dando 21,659 combinaciones de clasificador en los conjunto de datos.
Ellos encontraron errores en los clasificadores en algunos fue la afectación de la debido a la colinealidad de los datos, matrices de covarianza singulares, e insumos iguales para todos los patrones de entrenamiento en algunas clases donde se excluyen esto problemas donde representan el 2.1% de los 21,659  casos. 
El resultado se compara con el conjunto de datos de prueba. Con el fin de mantener poco costo computacional del trabajo experimental. Ellos son conscientes “de que esta La metodología puede llevar a un sesgo y varianza deficientes, y el resultado del clasificador para cada dato”.
Como Conclusión del papper ellos encontraron que el mejor método después de hacer una evaluación exhaustiva en la 17 familias en toda la base de datos de clasificación de aprendizaje automático de la UCI, que los mejores resultado fueron lo método de random forest logra en promedio el 94.1% de la máxima precisión en todos los conjuntos de datos.


