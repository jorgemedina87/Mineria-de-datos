{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import os\n",
    "#print(os.listdir(\"../input\"))\n",
    "\n",
    "from string import punctuation\n",
    "from keras.models import Sequential,Model\n",
    "from keras.layers import Embedding,Input,Activation,Flatten,CuDNNLSTM,Dense,Dropout,Bidirectional\n",
    "from keras.layers import Convolution1D,GlobalAveragePooling1D\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import LeakyReLU\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import gc\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading the CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"input/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>severe_toxicity</th>\n",
       "      <th>obscene</th>\n",
       "      <th>identity_attack</th>\n",
       "      <th>insult</th>\n",
       "      <th>threat</th>\n",
       "      <th>asian</th>\n",
       "      <th>atheist</th>\n",
       "      <th>...</th>\n",
       "      <th>article_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>funny</th>\n",
       "      <th>wow</th>\n",
       "      <th>sad</th>\n",
       "      <th>likes</th>\n",
       "      <th>disagree</th>\n",
       "      <th>sexual_explicit</th>\n",
       "      <th>identity_annotator_count</th>\n",
       "      <th>toxicity_annotator_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59848</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>This is so cool. It's like, 'would you want yo...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2006</td>\n",
       "      <td>rejected</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>59849</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Thank you!! This would make my life a lot less...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2006</td>\n",
       "      <td>rejected</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>59852</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>This is such an urgent design problem; kudos t...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2006</td>\n",
       "      <td>rejected</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>59855</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Is this something I'll be able to install on m...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2006</td>\n",
       "      <td>rejected</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>59856</td>\n",
       "      <td>0.893617</td>\n",
       "      <td>haha you guys are a bunch of losers.</td>\n",
       "      <td>0.021277</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.021277</td>\n",
       "      <td>0.87234</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2006</td>\n",
       "      <td>rejected</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id    target                                       comment_text  \\\n",
       "0  59848  0.000000  This is so cool. It's like, 'would you want yo...   \n",
       "1  59849  0.000000  Thank you!! This would make my life a lot less...   \n",
       "2  59852  0.000000  This is such an urgent design problem; kudos t...   \n",
       "3  59855  0.000000  Is this something I'll be able to install on m...   \n",
       "4  59856  0.893617               haha you guys are a bunch of losers.   \n",
       "\n",
       "   severe_toxicity  obscene  identity_attack   insult  threat  asian  atheist  \\\n",
       "0         0.000000      0.0         0.000000  0.00000     0.0    NaN      NaN   \n",
       "1         0.000000      0.0         0.000000  0.00000     0.0    NaN      NaN   \n",
       "2         0.000000      0.0         0.000000  0.00000     0.0    NaN      NaN   \n",
       "3         0.000000      0.0         0.000000  0.00000     0.0    NaN      NaN   \n",
       "4         0.021277      0.0         0.021277  0.87234     0.0    0.0      0.0   \n",
       "\n",
       "   ...  article_id    rating  funny  wow  sad  likes  disagree  \\\n",
       "0  ...        2006  rejected      0    0    0      0         0   \n",
       "1  ...        2006  rejected      0    0    0      0         0   \n",
       "2  ...        2006  rejected      0    0    0      0         0   \n",
       "3  ...        2006  rejected      0    0    0      0         0   \n",
       "4  ...        2006  rejected      0    0    0      1         0   \n",
       "\n",
       "   sexual_explicit  identity_annotator_count  toxicity_annotator_count  \n",
       "0              0.0                         0                         4  \n",
       "1              0.0                         0                         4  \n",
       "2              0.0                         0                         4  \n",
       "3              0.0                         0                         4  \n",
       "4              0.0                         4                        47  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Converting Target Probabilities to 0 or 1 for making it categorical. All the values in target column that are above 0.5 are considered as 1 and rest are considered as 0.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def target(value):\n",
    "    if value>=0.5:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['target'] = train_df['target'].apply(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Getting out X and y variable. We will be training on the X variable and predicting the Y variable**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = train_df['comment_text']\n",
    "y = train_df['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using seaborn library to check the number of observations in each class that is 0 and 1. Countplot helps in visualization of the values.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7253cf2f28>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Performing some cleaning in the commnet text using regular expression. This code with help us extract only the characters from the expression.\n",
    "**\n",
    "**Tutorial for regular expressions can be found** [here](https://www.w3schools.com/python/python_regex.asp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\W+',' ',text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 1804874/1804874 [00:42<00:00, 42196.21it/s]\n"
     ]
    }
   ],
   "source": [
    "x = x.progress_apply(cleaning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using word embeddings so that words with similar words have similar representation in vector space. It represents every word as a vector. The words which have similar meaning are place close to each other. Quick understanding can be done from [this](https://towardsdatascience.com/word-embeddings-exploration-explanation-and-exploitation-with-code-in-python-5dac99d5d795) article.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "400000it [00:14, 27680.92it/s]\n"
     ]
    }
   ],
   "source": [
    "f = open('input/glove.6B.100d.txt',encoding=\"utf8\")\n",
    "embedding_values = {}\n",
    "for line in tqdm(f):\n",
    "    value = line.split(' ')\n",
    "    word = value[0]\n",
    "    coef = np.array(value[1:],dtype = 'float32')\n",
    "    embedding_values[word]=coef"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**These are the steps that needs to be performed so that we can convert each word of our vocabulary into a unique integer. Tokenizer is initalized in first step. Then fitting on the text will help us create a vocabulary so that each word is assigned with a unique integer. Then we convert in the whole sentence of the comment into a sequence of numbers which are assigned by the tokenizer.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "token.fit_on_texts(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence = token.texts_to_sequences(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1804874"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(sequence)+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Padding the sequence helps in making all the sentence of same length. maxlen is the parameter which decides the length we want to assign to all the sentences. Padding is done by adding 0 on either the end of sentence or prior the sentence if the sentence is having length less than max length. This is also a parameter which user can change, by defaults its prefix. If the length of the sentence is more than 100 then it is pruned which brings down the length to 100 (maxlen)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_seq = pad_sequences(sequence,maxlen = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now we will be converting each word in our vocabulary into word embeddings. This embedding is vector of 1x100 dimension which represents each word as a vector and placing them into a vector space. Embedding matrix is created in which the number assigned to the word by tokenizer is assigned with the corresponding vector which we get from the glove embeddings.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████| 309011/309011 [00:00<00:00, 732189.14it/s]\n"
     ]
    }
   ],
   "source": [
    "embedding_matrix = np.zeros((vocab_size,100))\n",
    "for word,i in tqdm(token.word_index.items()):\n",
    "    values = embedding_values.get(word)\n",
    "    if values is not None:\n",
    "        embedding_matrix[i] = values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we start building the model with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here this embedding layer is important as this will help us in training of the sentences with their respective embeddings whihc we have assigned above. The first parameter is the size of our vocabulary. Second parameter is the output embeddings length which is 100 in this case as we used the 100 glove embeddings of each word. The length of each observation which is expected by the network is given by input_length parameter. We have padded all the observations to 100 hence we set input_length = 10. Weights parameter shows that the embeddings which we want to use is embeddings_matrix and it should not be altered hence trainable is kept false.\n",
    "If we want to train our own embeddings we can simply remove the weights and trainable parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\JORGE\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "model.add(Embedding(vocab_size,100,input_length = 100,weights = [embedding_matrix],trainable = False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building a LSTM model. LSTM networks are useful in sequence data as they are capable of remembering the past words which help them in understanding the meaning of the sentence which helps in text classification. Bidirectional Layer is helpful as it helps in understanding thesentence from start to end and also from end to start. It works in both the direction. This is useful as the reverse order LSTM layer is capable of learning patterns which are not possible for the normal LSTM layers which goes from start to end of the sentence in the normal order. Hence Bidirectional layers are useful in text classification problems as different patterns can be captured from 2 directions.\n",
    "CuDNNLSTM is same as LSTM. If you are using GPU then CuDNNLSTM will be faster but if you are using CPU please use LSTM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'CudnnLSTM' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-d2894641a6db>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBidirectional\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCudnnLSTM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mreturn_sequences\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mConvolution1D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'same'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mGlobalAveragePooling1D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'CudnnLSTM' is not defined"
     ]
    }
   ],
   "source": [
    "model.add(Bidirectional(CudnnLSTM(100,return_sequences=True)))\n",
    "model.add(Convolution1D(64,7,padding='same'))\n",
    "model.add(GlobalAveragePooling1D())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(128))\n",
    "model.add(LeakyReLU())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(64,activation = 'relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(1,activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam',loss='binary_crossentropy',metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(pad_seq,y,test_size = 0.15,random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1534142 samples, validate on 270732 samples\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "No OpKernel was registered to support Op 'CudnnRNN' used by node bidirectional_1/CudnnRNN (defined at C:\\Users\\JORGE\\Anaconda3\\lib\\site-packages\\keras\\layers\\cudnn_recurrent.py:517) with these attrs: [is_training=true, seed2=0, input_mode=\"linear_input\", T=DT_FLOAT, dropout=0, rnn_mode=\"lstm\", direction=\"unidirectional\", seed=87654321]\nRegistered devices: [CPU]\nRegistered kernels:\n  <no registered kernels>\n\n\t [[node bidirectional_1/CudnnRNN (defined at C:\\Users\\JORGE\\Anaconda3\\lib\\site-packages\\keras\\layers\\cudnn_recurrent.py:517) ]]\n\nCaused by op 'bidirectional_1/CudnnRNN', defined at:\n  File \"C:\\Users\\JORGE\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\JORGE\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\JORGE\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\JORGE\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\JORGE\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"C:\\Users\\JORGE\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\Users\\JORGE\\Anaconda3\\lib\\asyncio\\base_events.py\", line 539, in run_forever\n    self._run_once()\n  File \"C:\\Users\\JORGE\\Anaconda3\\lib\\asyncio\\base_events.py\", line 1775, in _run_once\n    handle._run()\n  File \"C:\\Users\\JORGE\\Anaconda3\\lib\\asyncio\\events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"C:\\Users\\JORGE\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"C:\\Users\\JORGE\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"C:\\Users\\JORGE\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 781, in inner\n    self.run()\n  File \"C:\\Users\\JORGE\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 742, in run\n    yielded = self.gen.send(value)\n  File \"C:\\Users\\JORGE\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"C:\\Users\\JORGE\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\JORGE\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"C:\\Users\\JORGE\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\JORGE\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"C:\\Users\\JORGE\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\JORGE\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\JORGE\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\JORGE\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2848, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"C:\\Users\\JORGE\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2874, in _run_cell\n    return runner(coro)\n  File \"C:\\Users\\JORGE\\Anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"C:\\Users\\JORGE\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3049, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\JORGE\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3214, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"C:\\Users\\JORGE\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3296, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-21-849dbc0336b9>\", line 1, in <module>\n    model.add(Bidirectional(CuDNNLSTM(100,return_sequences=True)))\n  File \"C:\\Users\\JORGE\\Anaconda3\\lib\\site-packages\\keras\\engine\\sequential.py\", line 181, in add\n    output_tensor = layer(self.outputs[0])\n  File \"C:\\Users\\JORGE\\Anaconda3\\lib\\site-packages\\keras\\layers\\wrappers.py\", line 427, in __call__\n    return super(Bidirectional, self).__call__(inputs, **kwargs)\n  File \"C:\\Users\\JORGE\\Anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 457, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"C:\\Users\\JORGE\\Anaconda3\\lib\\site-packages\\keras\\layers\\wrappers.py\", line 522, in call\n    y = self.forward_layer.call(inputs, **kwargs)\n  File \"C:\\Users\\JORGE\\Anaconda3\\lib\\site-packages\\keras\\layers\\cudnn_recurrent.py\", line 90, in call\n    output, states = self._process_batch(inputs, initial_state)\n  File \"C:\\Users\\JORGE\\Anaconda3\\lib\\site-packages\\keras\\layers\\cudnn_recurrent.py\", line 517, in _process_batch\n    is_training=True)\n  File \"C:\\Users\\JORGE\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\cudnn_rnn\\python\\ops\\cudnn_rnn_ops.py\", line 1636, in __call__\n    input_data, input_h, input_c, params, is_training=is_training)\n  File \"C:\\Users\\JORGE\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\cudnn_rnn\\python\\ops\\cudnn_rnn_ops.py\", line 1527, in __call__\n    seed=self._seed)\n  File \"C:\\Users\\JORGE\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\cudnn_rnn\\python\\ops\\cudnn_rnn_ops.py\", line 1014, in _cudnn_rnn\n    outputs, output_h, output_c, _ = gen_cudnn_rnn_ops.cudnn_rnn(**args)\n  File \"C:\\Users\\JORGE\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_cudnn_rnn_ops.py\", line 141, in cudnn_rnn\n    seed2=seed2, is_training=is_training, name=name)\n  File \"C:\\Users\\JORGE\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\JORGE\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\Users\\JORGE\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3300, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\JORGE\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1801, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): No OpKernel was registered to support Op 'CudnnRNN' used by node bidirectional_1/CudnnRNN (defined at C:\\Users\\JORGE\\Anaconda3\\lib\\site-packages\\keras\\layers\\cudnn_recurrent.py:517) with these attrs: [is_training=true, seed2=0, input_mode=\"linear_input\", T=DT_FLOAT, dropout=0, rnn_mode=\"lstm\", direction=\"unidirectional\", seed=87654321]\nRegistered devices: [CPU]\nRegistered kernels:\n  <no registered kernels>\n\n\t [[node bidirectional_1/CudnnRNN (defined at C:\\Users\\JORGE\\Anaconda3\\lib\\site-packages\\keras\\layers\\cudnn_recurrent.py:517) ]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1333\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1334\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1335\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1316\u001b[0m       \u001b[1;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1317\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_extend_graph\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1351\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session_run_lock\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1352\u001b[1;33m       \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExtendSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1353\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: No OpKernel was registered to support Op 'CudnnRNN' used by {{node bidirectional_1/CudnnRNN}}with these attrs: [is_training=true, seed2=0, input_mode=\"linear_input\", T=DT_FLOAT, dropout=0, rnn_mode=\"lstm\", direction=\"unidirectional\", seed=87654321]\nRegistered devices: [CPU]\nRegistered kernels:\n  <no registered kernels>\n\n\t [[{{node bidirectional_1/CudnnRNN}}]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-0f7370475dd7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2695\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2696\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2697\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_make_callable_from_options'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2698\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_sparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2699\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36mget_session\u001b[1;34m()\u001b[0m\n\u001b[0;32m    197\u001b[0m                 \u001b[1;31m# not already marked as initialized.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m                 is_initialized = session.run(\n\u001b[1;32m--> 199\u001b[1;33m                     [tf.is_variable_initialized(v) for v in candidate_vars])\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0muninitialized_vars\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mflag\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_initialized\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcandidate_vars\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    927\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 929\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    930\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1150\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1152\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1153\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1328\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1329\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1330\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1346\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1347\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1348\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1349\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1350\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: No OpKernel was registered to support Op 'CudnnRNN' used by node bidirectional_1/CudnnRNN (defined at C:\\Users\\JORGE\\Anaconda3\\lib\\site-packages\\keras\\layers\\cudnn_recurrent.py:517) with these attrs: [is_training=true, seed2=0, input_mode=\"linear_input\", T=DT_FLOAT, dropout=0, rnn_mode=\"lstm\", direction=\"unidirectional\", seed=87654321]\nRegistered devices: [CPU]\nRegistered kernels:\n  <no registered kernels>\n\n\t [[node bidirectional_1/CudnnRNN (defined at C:\\Users\\JORGE\\Anaconda3\\lib\\site-packages\\keras\\layers\\cudnn_recurrent.py:517) ]]\n\nCaused by op 'bidirectional_1/CudnnRNN', defined at:\n  File \"C:\\Users\\JORGE\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\JORGE\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\JORGE\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\JORGE\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\JORGE\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"C:\\Users\\JORGE\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\Users\\JORGE\\Anaconda3\\lib\\asyncio\\base_events.py\", line 539, in run_forever\n    self._run_once()\n  File \"C:\\Users\\JORGE\\Anaconda3\\lib\\asyncio\\base_events.py\", line 1775, in _run_once\n    handle._run()\n  File \"C:\\Users\\JORGE\\Anaconda3\\lib\\asyncio\\events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"C:\\Users\\JORGE\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"C:\\Users\\JORGE\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"C:\\Users\\JORGE\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 781, in inner\n    self.run()\n  File \"C:\\Users\\JORGE\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 742, in run\n    yielded = self.gen.send(value)\n  File \"C:\\Users\\JORGE\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"C:\\Users\\JORGE\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\JORGE\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"C:\\Users\\JORGE\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\JORGE\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"C:\\Users\\JORGE\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\JORGE\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\JORGE\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\JORGE\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2848, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"C:\\Users\\JORGE\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2874, in _run_cell\n    return runner(coro)\n  File \"C:\\Users\\JORGE\\Anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"C:\\Users\\JORGE\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3049, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\JORGE\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3214, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"C:\\Users\\JORGE\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3296, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-21-849dbc0336b9>\", line 1, in <module>\n    model.add(Bidirectional(CuDNNLSTM(100,return_sequences=True)))\n  File \"C:\\Users\\JORGE\\Anaconda3\\lib\\site-packages\\keras\\engine\\sequential.py\", line 181, in add\n    output_tensor = layer(self.outputs[0])\n  File \"C:\\Users\\JORGE\\Anaconda3\\lib\\site-packages\\keras\\layers\\wrappers.py\", line 427, in __call__\n    return super(Bidirectional, self).__call__(inputs, **kwargs)\n  File \"C:\\Users\\JORGE\\Anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 457, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"C:\\Users\\JORGE\\Anaconda3\\lib\\site-packages\\keras\\layers\\wrappers.py\", line 522, in call\n    y = self.forward_layer.call(inputs, **kwargs)\n  File \"C:\\Users\\JORGE\\Anaconda3\\lib\\site-packages\\keras\\layers\\cudnn_recurrent.py\", line 90, in call\n    output, states = self._process_batch(inputs, initial_state)\n  File \"C:\\Users\\JORGE\\Anaconda3\\lib\\site-packages\\keras\\layers\\cudnn_recurrent.py\", line 517, in _process_batch\n    is_training=True)\n  File \"C:\\Users\\JORGE\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\cudnn_rnn\\python\\ops\\cudnn_rnn_ops.py\", line 1636, in __call__\n    input_data, input_h, input_c, params, is_training=is_training)\n  File \"C:\\Users\\JORGE\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\cudnn_rnn\\python\\ops\\cudnn_rnn_ops.py\", line 1527, in __call__\n    seed=self._seed)\n  File \"C:\\Users\\JORGE\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\cudnn_rnn\\python\\ops\\cudnn_rnn_ops.py\", line 1014, in _cudnn_rnn\n    outputs, output_h, output_c, _ = gen_cudnn_rnn_ops.cudnn_rnn(**args)\n  File \"C:\\Users\\JORGE\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_cudnn_rnn_ops.py\", line 141, in cudnn_rnn\n    seed2=seed2, is_training=is_training, name=name)\n  File \"C:\\Users\\JORGE\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\JORGE\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\Users\\JORGE\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3300, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\JORGE\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1801, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): No OpKernel was registered to support Op 'CudnnRNN' used by node bidirectional_1/CudnnRNN (defined at C:\\Users\\JORGE\\Anaconda3\\lib\\site-packages\\keras\\layers\\cudnn_recurrent.py:517) with these attrs: [is_training=true, seed2=0, input_mode=\"linear_input\", T=DT_FLOAT, dropout=0, rnn_mode=\"lstm\", direction=\"unidirectional\", seed=87654321]\nRegistered devices: [CPU]\nRegistered kernels:\n  <no registered kernels>\n\n\t [[node bidirectional_1/CudnnRNN (defined at C:\\Users\\JORGE\\Anaconda3\\lib\\site-packages\\keras\\layers\\cudnn_recurrent.py:517) ]]\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train,y_train,epochs = 2,batch_size=128,validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = history.history\n",
    "validation_acc = values['val_acc']\n",
    "training_acc = values['acc']\n",
    "validation_loss = values['loss']\n",
    "training_loss = values['val_loss']\n",
    "epochs = range(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting a graph between Training and Testing Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epochs,training_acc,label = 'Training Accuracy')\n",
    "plt.plot(epochs,validation_acc,label = 'Validation Accuracy')\n",
    "plt.title('Epochs vs Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting a graph between Training and Testing Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epochs,training_loss,label = 'Training Loss')\n",
    "plt.plot(epochs,validation_loss,label = 'Validation Loss')\n",
    "plt.title('Epochs vs Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('../input/jigsaw-unintended-bias-in-toxicity-classification/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = test['comment_text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing of the test data so that model can easily make its prediction as it should be in the same format as that of our training data.\n",
    "Note that we are using the same tokenizer in our testing and we are not fitting it again becuase this might change the numbers assigned to words which are there in the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sequence = token.texts_to_sequences(X)\n",
    "test_pad_seq = pad_sequences(test_sequence,maxlen = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(test_pad_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame([test['id']]).T\n",
    "submission['prediction'] = prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
